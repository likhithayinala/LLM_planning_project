{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c2c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from detection_model import select_det_model\n",
    "from main_model import select_main_model\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataloader import dataset\n",
    "import logging\n",
    "import wandb\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a71a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util funcs\n",
    "def create_dir(path):\n",
    "    \"\"\"\n",
    "    Creates a directory if it does not exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        print(\"Creating path: \", path)\n",
    "        os.makedirs(path)\n",
    "        \n",
    "def set_config(config_dict):\n",
    "    with open(config_dict['config']) as f:\n",
    "        config = json.load(f)\n",
    "    config.update(config_dict)\n",
    "    if config.get('debug', False):\n",
    "        config.update({'wandb': False, 'log': False})\n",
    "    if config['wandb']:\n",
    "        wandb.init(project='bad_content_detection', config=config)\n",
    "    config = results(config)\n",
    "    return config\n",
    "\n",
    "def results(config):\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36b4fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inits\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4957a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'config': 'config.json',\n",
    "    'detection_model': 'MLP',\n",
    "    'main_model': 'Llama2',\n",
    "    'dataset': 'CIFAR10',\n",
    "    'debug': False,\n",
    "    'wandb': True,\n",
    "    'log': True,\n",
    "    'tag': '',\n",
    "    'layer': 0,\n",
    "    'token': 0\n",
    "}\n",
    "config = set_config(config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1267e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "detection_model = select_det_model('MLP', config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d298ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights\n",
    "detection_model.load_state_dict(torch.load('/home/sv2795_columbia_edu/GENAI_Project/src/results/MLP_Llama2_CIFAR10_MLP-last-layer-firsrt-token-refusal-big/best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a919ba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init test set\n",
    "data = pd.read_csv(config['dataset_path'])\n",
    "test_data = data[int(len(data)*0.9):].reset_index(drop=True)\n",
    "test_dataloader = DataLoader(dataset(test_data,config), batch_size=config['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec9de5f",
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "# Run test\n",
    "total_samples = 0\n",
    "total_correct = 0\n",
    "misclassified = []\n",
    "classified = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        response, safety_class, token_hidden_states, prompt_hidden_states = data\n",
    "        state = token_hidden_states[:,config['layer'] - 1,config['token'] - 1,:]\n",
    "        state, labels = state.to(device), safety_class.to(device)\n",
    "        output = detection_model(state)\n",
    "        labels = labels.to(torch.long)\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        #print(labels,predicted)\n",
    "        total_samples += labels.size(0)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        for i in range(labels.size(0)):\n",
    "            if predicted[i] != labels[i]:\n",
    "                misclassified.append({\"response\": response[i], \"predicted\": predicted[i].item(), \"label\": labels[i].item()})\n",
    "            else:\n",
    "                classified.append({\"response\": response[i], \"predicted\": predicted[i].item(), \"label\": labels[i].item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3049c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy\n",
    "test_accuracy = 100 * total_correct / total_samples\n",
    "print(\"test accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1778566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save misclassified results\n",
    "classified_df = pd.DataFrame(classified)\n",
    "classified_df.to_csv(\"classified_mlp.csv\", index = False)\n",
    "classified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb11f1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Print some true positives\n",
    "classified_df = classified_df.sample(frac=1).reset_index(drop=True)\n",
    "true_positives = classified_df[(classified_df[\"predicted\"] == 1) & (classified_df[\"label\"] == 1)]\n",
    "true_pos = true_positives[\"response\"]\n",
    "for i in range(5):\n",
    "    print(true_pos.iloc[i])\n",
    "    print(\"***********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbcaa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some true negatives\n",
    "classified_df = classified_df.sample(frac=1).reset_index(drop=True)\n",
    "true_neg = classified_df[(classified_df[\"predicted\"] == 0) & (classified_df[\"label\"] == 0)]\n",
    "true_neg = true_neg[\"response\"]\n",
    "for i in range(5):\n",
    "    print(true_neg.iloc[i])\n",
    "    print(\"***********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecc6825",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Print some false positives\n",
    "misclassified_df = misclassified_df.sample(frac=1).reset_index(drop=True)\n",
    "false_positives = misclassified_df[(misclassified_df[\"predicted\"] == 1) & (misclassified_df[\"label\"] == 0)]\n",
    "false_positive_responses = false_positives[\"response\"]\n",
    "for i in range(5):\n",
    "    print(false_positive_responses.iloc[i])\n",
    "    print(\"***********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10340c19",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Print some false negatives. \n",
    "misclassified_df = misclassified_df.sample(frac=1).reset_index(drop=True)\n",
    "false_negative = misclassified_df[(misclassified_df[\"predicted\"] == 0) & (misclassified_df[\"label\"] == 1)]\n",
    "false_negative = false_negative[\"response\"]\n",
    "for i in range(5):\n",
    "    print(false_negative.iloc[i])\n",
    "    print(\"***********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbe812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also print precision and recall\n",
    "precision = len(true_pos) / (len(true_pos) + len(false_positives))\n",
    "print(\"Precision: \", precision)\n",
    "recall = len(true_pos) / (len(true_pos) + len(false_negative))\n",
    "print(\"recall: \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4bbcf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
